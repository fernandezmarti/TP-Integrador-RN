{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e6ccca9e-4fec-44af-a8b7-d034101cb913",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "99449de6-85e8-41e9-b4ea-7e50866d1207",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f3eea338-d373-4d32-8815-54ba0a156e3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///c:/Users/sanit/OneDrive/Escritorio/TP%20integrador%20NN/TP-Integrador-RN/mlruns/238164930765243842', creation_time=1749337243079, experiment_id='238164930765243842', last_update_time=1749337243079, lifecycle_stage='active', name='MLP_Clasificador_Imagenes', tags={}>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(\"MLP_Clasificador_Imagenes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d21eeefb-bc83-4931-acbc-65ca26d10cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision.utils as vutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "573d2f49-abfd-444a-a947-712c1737eb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para loguear una figura matplotlib en TensorBoard\n",
    "def plot_to_tensorboard(fig, writer, tag, step):\n",
    "    buf = io.BytesIO()\n",
    "    fig.savefig(buf, format='png')\n",
    "    buf.seek(0)\n",
    "    image = Image.open(buf).convert(\"RGB\")\n",
    "    image = np.array(image)\n",
    "    image = torch.tensor(image).permute(2, 0, 1) / 255.0\n",
    "    writer.add_image(tag, image, global_step=step)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4901b00e-6c31-4af2-ab6d-1cc383687d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para matriz de confusión y clasificación\n",
    "def log_classification_report(model, loader, writer, step, prefix=\"val\"):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.numpy())\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    fig_cm, ax = plt.subplots(figsize=(6, 6))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=train_dataset.label_encoder.classes_)\n",
    "    disp.plot(ax=ax, cmap='Blues', xticks_rotation=45)\n",
    "    ax.set_title(f'{prefix.title()} - Confusion Matrix')\n",
    "\n",
    "    # Guardar localmente y subir a MLflow\n",
    "    fig_path = f\"confusion_matrix_{prefix}_epoch_{step}.png\"\n",
    "    fig_cm.savefig(fig_path)\n",
    "    mlflow.log_artifact(fig_path)\n",
    "    os.remove(fig_path)\n",
    "\n",
    "    plot_to_tensorboard(fig_cm, writer, f\"{prefix}/confusion_matrix\", step)\n",
    "\n",
    "    cls_report = classification_report(all_labels, all_preds, target_names=train_dataset.label_encoder.classes_)\n",
    "    writer.add_text(f\"{prefix}/classification_report\", f\"<pre>{cls_report}</pre>\", step)\n",
    "\n",
    "    # También loguear texto del reporte\n",
    "    with open(f\"classification_report_{prefix}_epoch_{step}.txt\", \"w\") as f:\n",
    "        f.write(cls_report)\n",
    "    mlflow.log_artifact(f.name)\n",
    "    os.remove(f.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2d6564e0-f970-461a-8ab4-5d19e0d55040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear directorio de logs\n",
    "log_dir = \"runs/mlp_experimento_1\"\n",
    "writer = SummaryWriter(log_dir=log_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "41919c3b-76d8-4eb0-810a-62ce743752de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "\n",
    "        class_names = sorted(os.listdir(root_dir))\n",
    "        self.class_to_idx = {cls: idx for idx, cls in enumerate(class_names)}\n",
    "\n",
    "        for cls in class_names:\n",
    "            cls_dir = os.path.join(root_dir, cls)\n",
    "            for fname in os.listdir(cls_dir):\n",
    "                if fname.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "                    self.image_paths.append(os.path.join(cls_dir, fname))\n",
    "                    self.labels.append(cls)\n",
    "\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.labels = self.label_encoder.fit_transform(self.labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = np.array(Image.open(self.image_paths[idx]).convert(\"RGB\"))\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented[\"image\"]\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1bc0d2e4-319e-4f95-a59b-565182681864",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = A.Compose([\n",
    "    A.Resize(64, 64),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.2),\n",
    "    A.Normalize(),\n",
    "    ToTensorV2()\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "32743888-c68f-4a1a-a5e0-afe766b91486",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_test_transform = A.Compose([\n",
    "    A.Resize(64, 64),\n",
    "    A.Normalize(),\n",
    "    ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a707a13e-87cc-4c2b-89fd-b83ff1fd9d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "train_dir = r'skin-dataset-clasification/data/Split_smol/train/'\n",
    "val_dir = r'skin-dataset-clasification/data/Split_smol/val/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5e18375e-9fb1-4084-8338-302ca99f8744",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomImageDataset(train_dir, transform=train_transform)\n",
    "val_dataset   = CustomImageDataset(val_dir, transform=val_test_transform)\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9a9d4d33-e68d-4ccb-8b0e-f18deabc659b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, input_size=64*64*3, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(input_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "585580ed-3db0-4687-8ab5-a09abacc621b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_classes = len(set(train_dataset.labels))\n",
    "model = MLPClassifier(num_classes=num_classes).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "da9b8088-283f-4549-8c86-2fec28283e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento y validación\n",
    "def evaluate(model, loader, epoch=None, prefix=\"val\"):\n",
    "    log_classification_report(model, val_loader, writer, step=epoch, prefix=\"val\")\n",
    "    model.eval()\n",
    "    correct, total, loss_sum = 0, 0, 0.0\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (images, labels) in enumerate(loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            loss_sum += loss.item()\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "            # Loguear imágenes del primer batch\n",
    "            if i == 0 and epoch is not None:\n",
    "                img_grid = vutils.make_grid(images[:8].cpu(), normalize=True)\n",
    "                writer.add_image(f\"{prefix}/images\", img_grid, global_step=epoch)\n",
    "\n",
    "    acc = 100.0 * correct / total\n",
    "    avg_loss = loss_sum / len(loader)\n",
    "\n",
    "    if epoch is not None:\n",
    "        writer.add_scalar(f\"{prefix}/loss\", avg_loss, epoch)\n",
    "        writer.add_scalar(f\"{prefix}/accuracy\", acc, epoch)\n",
    "\n",
    "    return avg_loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a08d5e76-139b-43b0-a5f0-a781b0a22463",
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Run with UUID 189e3c5303a24ed4bc9a521ec03fb531 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mException\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[41]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Loop de entrenamiento\u001b[39;00m\n\u001b[32m      2\u001b[39m n_epochs = \u001b[32m10\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mmlflow\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstart_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m      4\u001b[39m     \u001b[38;5;66;03m# Log hiperparámetros\u001b[39;00m\n\u001b[32m      5\u001b[39m     mlflow.log_params({\n\u001b[32m      6\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mMLPClassifier\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      7\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33minput_size\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m64\u001b[39m*\u001b[32m64\u001b[39m*\u001b[32m3\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     14\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mval_dir\u001b[39m\u001b[33m\"\u001b[39m: val_dir,\n\u001b[32m     15\u001b[39m     })\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_epochs):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sanit\\OneDrive\\Escritorio\\TP integrador NN\\TP-Integrador-RN\\.venv\\Lib\\site-packages\\mlflow\\tracking\\fluent.py:351\u001b[39m, in \u001b[36mstart_run\u001b[39m\u001b[34m(run_id, experiment_id, run_name, nested, parent_run_id, tags, description, log_system_metrics)\u001b[39m\n\u001b[32m    349\u001b[39m experiment_id = \u001b[38;5;28mstr\u001b[39m(experiment_id) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(experiment_id, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m experiment_id\n\u001b[32m    350\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(active_run_stack) > \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m nested:\n\u001b[32m--> \u001b[39m\u001b[32m351\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\n\u001b[32m    352\u001b[39m         (\n\u001b[32m    353\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mRun with UUID \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m is already active. To start a new run, first end the \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    354\u001b[39m             + \u001b[33m\"\u001b[39m\u001b[33mcurrent run with mlflow.end_run(). To start a nested \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    355\u001b[39m             + \u001b[33m\"\u001b[39m\u001b[33mrun, call start_run with nested=True\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    356\u001b[39m         ).format(active_run_stack[\u001b[32m0\u001b[39m].info.run_id)\n\u001b[32m    357\u001b[39m     )\n\u001b[32m    358\u001b[39m client = MlflowClient()\n\u001b[32m    359\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m run_id:\n",
      "\u001b[31mException\u001b[39m: Run with UUID 189e3c5303a24ed4bc9a521ec03fb531 is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True"
     ]
    }
   ],
   "source": [
    "# Loop de entrenamiento\n",
    "n_epochs = 10\n",
    "with mlflow.start_run():\n",
    "    # Log hiperparámetros\n",
    "    mlflow.log_params({\n",
    "        \"model\": \"MLPClassifier\",\n",
    "        \"input_size\": 64*64*3,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"lr\": 1e-3,\n",
    "        \"epochs\": n_epochs,\n",
    "        \"optimizer\": \"Adam\",\n",
    "        \"loss_fn\": \"CrossEntropyLoss\",\n",
    "        \"train_dir\": train_dir,\n",
    "        \"val_dir\": val_dir,\n",
    "    })\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{n_epochs}\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_acc = 100.0 * correct / total\n",
    "    val_loss, val_acc = evaluate(model, val_loader, epoch=epoch, prefix=\"val\")\n",
    "\n",
    "    print(f\"Epoch {epoch+1}:\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f}, Accuracy: {train_acc:.2f}%\")\n",
    "    print(f\"  Val   Loss: {val_loss:.4f}, Accuracy: {val_acc:.2f}%\")\n",
    "\n",
    "    writer.add_scalar(\"train/loss\", train_loss, epoch)\n",
    "    writer.add_scalar(\"train/accuracy\", train_acc, epoch)\n",
    "\n",
    "    # Log en MLflow\n",
    "    mlflow.log_metrics({\n",
    "        \"train_loss\": train_loss,\n",
    "        \"train_accuracy\": train_acc,\n",
    "        \"val_loss\": val_loss,\n",
    "        \"val_accuracy\": val_acc\n",
    "    }, step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7a8964-f0dc-439c-b18b-b084c1afe531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo guardado como 'mlp_model.pth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/08 08:31:41 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo guardado como 'mlp_model.pth'\n"
     ]
    }
   ],
   "source": [
    "# Guardar modelo\n",
    "torch.save(model.state_dict(), \"mlp_model.pth\")\n",
    "print(\"Modelo guardado como 'mlp_model.pth'\")\n",
    "mlflow.log_artifact(\"mlp_model.pth\")\n",
    "mlflow.pytorch.log_model(model, artifact_path=\"pytorch_model\")\n",
    "print(\"Modelo guardado como 'mlp_model.pth'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551ce1c4-58b3-4abf-8eb7-107b760ba69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorboard --logdir=runs/mlp_experimento_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30951f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad787c6a",
   "metadata": {},
   "source": [
    "http://localhost:6006 para ver el tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe604f20",
   "metadata": {},
   "source": [
    "## Acividades de Modificacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6b1701-9f75-45e7-9992-5758d9af612e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifierDropout(nn.Module):\n",
    "    def __init__(self, input_size=64*64*3, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(input_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbf3631",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"runs/mlp_experimento_2_dropout\"\n",
    "writer = SummaryWriter(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc3ef99",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_model=MLPClassifierDropout(num_classes=num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709b0e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 22/22 [00:09<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "  Train Loss: 0.6460, Accuracy: 75.86%\n",
      "  Val   Loss: 1.2626, Accuracy: 56.11%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 22/22 [00:10<00:00,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:\n",
      "  Train Loss: 0.6619, Accuracy: 73.99%\n",
      "  Val   Loss: 1.2271, Accuracy: 59.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 22/22 [00:10<00:00,  2.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:\n",
      "  Train Loss: 0.6558, Accuracy: 74.43%\n",
      "  Val   Loss: 1.2146, Accuracy: 60.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 22/22 [00:09<00:00,  2.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4:\n",
      "  Train Loss: 0.6494, Accuracy: 74.86%\n",
      "  Val   Loss: 1.2437, Accuracy: 60.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 22/22 [00:10<00:00,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5:\n",
      "  Train Loss: 0.5905, Accuracy: 77.16%\n",
      "  Val   Loss: 1.2653, Accuracy: 57.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 22/22 [00:11<00:00,  1.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:\n",
      "  Train Loss: 0.5757, Accuracy: 77.73%\n",
      "  Val   Loss: 1.3651, Accuracy: 57.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 22/22 [00:10<00:00,  2.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7:\n",
      "  Train Loss: 0.5934, Accuracy: 76.87%\n",
      "  Val   Loss: 1.3460, Accuracy: 58.89%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 22/22 [00:10<00:00,  2.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8:\n",
      "  Train Loss: 0.6453, Accuracy: 76.01%\n",
      "  Val   Loss: 1.2588, Accuracy: 57.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 22/22 [00:08<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9:\n",
      "  Train Loss: 0.5742, Accuracy: 78.02%\n",
      "  Val   Loss: 1.4501, Accuracy: 60.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 22/22 [00:08<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10:\n",
      "  Train Loss: 0.5498, Accuracy: 79.60%\n",
      "  Val   Loss: 1.4321, Accuracy: 56.11%\n"
     ]
    }
   ],
   "source": [
    "# Loop de entrenamiento\n",
    "n_epochs = 10\n",
    "with mlflow.start_run():\n",
    "    # Log hiperparámetros\n",
    "    mlflow.log_params({\n",
    "        \"model\": \"MLPClassifier with dropout\",\n",
    "        \"input_size\": 64*64*3,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"lr\": 1e-3,\n",
    "        \"epochs\": n_epochs,\n",
    "        \"optimizer\": \"Adam\",\n",
    "        \"loss_fn\": \"CrossEntropyLoss\",\n",
    "        \"train_dir\": train_dir,\n",
    "        \"val_dir\": val_dir,\n",
    "    })\n",
    "for epoch in range(n_epochs):\n",
    "    dropout_model.train()\n",
    "    running_loss = 0.0\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{n_epochs}\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_acc = 100.0 * correct / total\n",
    "    val_loss, val_acc = evaluate(model, val_loader, epoch=epoch, prefix=\"val\")\n",
    "\n",
    "    print(f\"Epoch {epoch+1}:\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f}, Accuracy: {train_acc:.2f}%\")\n",
    "    print(f\"  Val   Loss: {val_loss:.4f}, Accuracy: {val_acc:.2f}%\")\n",
    "\n",
    "    writer.add_scalar(\"train/loss\", train_loss, epoch)\n",
    "    writer.add_scalar(\"train/accuracy\", train_acc, epoch)\n",
    "\n",
    "    # Log en MLflow\n",
    "    mlflow.log_metrics({\n",
    "        \"train_loss\": train_loss,\n",
    "        \"train_accuracy\": train_acc,\n",
    "        \"val_loss\": val_loss,\n",
    "        \"val_accuracy\": val_acc\n",
    "    }, step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "33fa2869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo guardado como 'mlp_dropout_model.pth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/08 08:35:59 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo guardado como 'mlp_dropout_model.pth'\n"
     ]
    }
   ],
   "source": [
    "torch.save(dropout_model.state_dict(), \"mlp_dropout_model.pth\")\n",
    "print(\"Modelo guardado como 'mlp_dropout_model.pth'\")\n",
    "mlflow.log_artifact(\"mlp_dropout_model.pth\")\n",
    "mlflow.pytorch.log_model(dropout_model, artifact_path=\"pytorch_model\")\n",
    "print(\"Modelo guardado como 'mlp_dropout_model.pth'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3951e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorboard --logdir=runs/mlp_experimento_2_dropout"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
