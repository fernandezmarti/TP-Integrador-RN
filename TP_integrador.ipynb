{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43c35112",
   "metadata": {},
   "source": [
    "# 1. Dataset y Preprocesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ed54d6",
   "metadata": {},
   "source": [
    "**- ¿Por qué es necesario redimensionar las imágenes a un tamaño fijo para una MLP?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f0443d",
   "metadata": {},
   "source": [
    "\n",
    "Al crear un modelo MPL con capas lineales, antes de entrenar, definimos un número fijo de entradas ya que aprenden pesos fijos para cada posición del vector que se irán actualizando, para cada neurona. Si el input son imágenes de distintas dimensiones, después del `flatten` tendríamos vectores de diferente tamaño y obtendríamos un error de dimension porque no tendríamos coincidencia de los pesos de la primera capa que siempre espera un tamaño fijo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e55305",
   "metadata": {},
   "source": [
    "**- ¿Qué ventajas ofrece Albumentations frente a otras librerías de transformación como `torchvision.transforms`?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc1c1ac",
   "metadata": {},
   "source": [
    "Albumentations es una librería que nos permite hacer probabilísticamente transformaciónes de imágenes como técnica de data agumentation y cuenta con una documentación bien detallada con varios ejemplos para aprender a usar sus funciones. Esta es una técnica de regularización para que el modelo generalaice mejor y reducir el riesgo de overfitting.\\\n",
    "Contiene funciones básicas como rotación, traslación y normalización pero además posee otras funcionalidades más complejas que permiten distorsionar la información para generar nuevas entradas como . Además, esta librería no solo funciona con simples imágenes en 2D si no que también permite trabajar con imágenes en 3D (como el caso de las imágenes médicas) y con videos. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7820a8b",
   "metadata": {},
   "source": [
    "**- ¿Qué hace `A.Normalize()`? ¿Por qué es importante antes de entrenar una red?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22a0ddd",
   "metadata": {},
   "source": [
    "`A.Normalize()` es una transformación de Albumentations que aplica varias técnicas para normalizar los valores de sus pixeles antes de ingresarlos a la red. La técnica de normalización específica (standard, image, image_per_channel, min_max, min_max_per_channel) puede seleccionarse con el parámetro normalization. Esta transformación convierte los valores de los píxeles, que pueden ir de 0 a 255, a una distribución normal al rededor del cero para cada canal. En el caso de la standard se aplica: `img = (img - mean) / std`. Esto favorece al modelo ya que las entradas quedan en una escala consistente y evita que ciertos canales dominen el aprendizaje por tener escalas más grandes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a44fb8",
   "metadata": {},
   "source": [
    "**- ¿Por qué convertimos las imágenes a `ToTensorV2()` al final de la pipeline?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4c76aa",
   "metadata": {},
   "source": [
    "Este es el último paso de la data aumentation y lo debemos hacer porque Albumentations trabaja con imágenes como numpy arrays pero nosotros para entrenar la red en PyTorch necesitamos de tensores, entonces con esa línea de código logramos convertir el array de la imágen después de sus respectivas transformaciones en el formato correcto para poder entrenar la red."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a615afe",
   "metadata": {},
   "source": [
    "# 2. Arquitectura del Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08837055",
   "metadata": {},
   "source": [
    "**- ¿Por qué usamos una red MLP en lugar de una CNN aquí? ¿Qué limitaciones tiene?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289ec934",
   "metadata": {},
   "source": [
    "Para la clasificación y procesamiento de imágenes una CNN suele ser la solución más elegída. Si bien el MLP se trata de un modelo más simple y fácil de implementar, no es una buena estrategia para la clasificación y análisis de imagenes dado que estas tiene patrones espaciales que la caracterizan (como su textura o bordes específicos) que en este caso, al convertirlo en un vector 1D después del ´flatten´, perdemos esa información estructural que puede ser importante en el caso de querer detectar por ejemplo anomalías en la piel o en muchos casos médicos. Por lo que no tiene mucho sentido esta estrategia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799a3019",
   "metadata": {},
   "source": [
    "**- ¿Qué hace la capa `Flatten()` al principio de la red?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7844d14b",
   "metadata": {},
   "source": [
    "La capa ´flatten()´ se encarga de convertir la imágen que está en 2D y varios canales (por lo general 3: R,G,B) en un vector unidimensional ya que al usar un MLP, las capas lineares solo admiten vectores de entrada. En nuestro caso, al trabajar con imágenes de 64x64 en los tres canales, la imagen después del flatten resulta en un vector de 64x64x3 elementos, es decir 12.288 elementos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb57dbd",
   "metadata": {},
   "source": [
    "**- ¿Qué función de activación se usó? ¿Por qué no usamos `Sigmoid` o `Tanh`?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ab4ce7",
   "metadata": {},
   "source": [
    "En el modelo simple se implementó la función de activación ReLU, con la forma convencional de una rampa que toma el valor 0 si la entrada x es negativa y lo mantiene igual si es positiva. Esta es la función estándar para redes neuronales porque, además de ser simple de implementar, evita el problema del \"vanishing gradient\".\\\n",
    "Este problema ocurre cuando los gradientes se vuelven muy pequeños impidiendo que los pesos se actualicen correctamente, es decir, la red deja de aprender. Al usar funciones como Sigmoid y Tanh, cuyas derivadas son menores a 1, el vanishing gradient es un problema. Al propagarse hacia atrás a través de muchas capas, esas derivadas se multiplican y se achican más en cada paso, haciendo que los gradientes se desvanezcan."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c128b446",
   "metadata": {},
   "source": [
    "**- ¿Qué parámetro del modelo deberíamos cambiar si aumentamos el tamaño de entrada de la imagen?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31eb4c2f",
   "metadata": {},
   "source": [
    "Si aumentamos el tamaño de la imagen de entrada, deberíamos modificar el `input_size=64*64*3` que representa la nueva cantidad de elementos que componenen al vector de 1D después de la capa de flatten para poder trabajar con la capa linear del MLP. Otra opción es, en el caso de tener imágenes de mayor tamaño y querer trabajar con menos elementos, podemos redimensionar la imágen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e244ce17",
   "metadata": {},
   "source": [
    "# 3. Entrenamiento y Optimización"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2b1b8d",
   "metadata": {},
   "source": [
    "**- ¿Qué hace `optimizer.zero_grad()`?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745eeb26",
   "metadata": {},
   "source": [
    "La función `optimizer.zero_grad()` en PyTorch se usa para reiniciar (poner en cero) los gradientes acumulados de todos los parámetros del modelo antes de calcular los nuevos gradientes en el paso de backpropagation. Esto es necesario para evitar acumular el gradiente de los cálculos anteriores en el nuevo paso."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88565e8",
   "metadata": {},
   "source": [
    "**- ¿Por qué usamos `CrossEntropyLoss()` en este caso?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ec5019",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "51cc4744",
   "metadata": {},
   "source": [
    "**- ¿Cómo afecta la elección del tamaño de batch (`batch_size`) al entrenamiento?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cce1c3e",
   "metadata": {},
   "source": [
    "El batch size (BS) es la cantidad de datos que se procesan en la red, antes de ajustar los pesos por backpropagation. Lo que se hace es dividir al conjunto de datos totales del entrenamiento en N grupos con una cantidad BS de datos, y el modelo va a procesar cada batch hasta cubrir todos los datos (1 epoch). Esto es un hiperparámetro que hay que ajustar dado que afecta principalmente la dinámica del modelo ya que determina la frecuencia de actualización de pesos y la capcaidad de generalización del modelo. Un BS grande permite actualizaciones más estables y acelera el entrenamiento pero se puede perder generalización si es muy grande, mientras que un BS pequeño permite actualizaciones más frecuentes y ruidosas, tiene mejor capacidad de generalización pero es más lento por época (tarda mas en entrenar con todos los datos)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3223efc",
   "metadata": {},
   "source": [
    "**- ¿Qué pasaría si no usamos `model.eval()` durante la validación?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb43dbbb",
   "metadata": {},
   "source": [
    "`model.eval()` se utiliza durante etapa de inferencia y validación. Funciona deshabilitando comportamientos específicos del entrenamiento y utilizando los parámetros aprendidos para obtener resultados consistentes. Por ejemplo, si la red incluye dropout, en entrenamiento es una herramienta muy útil contra el overfitting, ya que al apagar neuronas aleatoriamente hace que neuronas con pesos pequeños ganen protagonismo. Por otro lado, durante la validación, no apaga neuronas ya que se busca evaluar el comportamiento de toda la red."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6c6a26",
   "metadata": {},
   "source": [
    "# 4. Validación y Evaluación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55885b8",
   "metadata": {},
   "source": [
    "**- ¿Qué significa una accuracy del 70% en validación pero 90% en entrenamiento?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06204319",
   "metadata": {},
   "source": [
    "El *accuracy* es una métrica que evalúa el porcentaje de predicciones correctas (TP+TN/all data). Esta métrica es fácil de interpretar pero no es siempre la más útil, específicamente en el caso de clasificaciones binareas desbalanceadas.\\\n",
    "Tener un rendimiento tan alto en entrenamiento y sustancialmente más bajo en validación (un 20% menos) sugiere que estamos en presencia de un caso de *overfitting*. En este caso el modelo se ajusta demasiado bien a la distribución de datos de entrenamiento (aprende el patrón o detalles específicos) y deja de generalizar bien, y es por eso que al presentarle datos nuevos el desempeño es tanto peor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1e7af3",
   "metadata": {},
   "source": [
    "**- ¿Qué otras métricas podrían ser más relevantes que accuracy en un problema real?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd01da3",
   "metadata": {},
   "source": [
    "la pérdida (loss), la precisión (accuracy), la tasa de aprendizaje y otros indicadores relevantes\n",
    "\n",
    "Las métricas más relevantes depende del problema a resolver, suele resultar útil complementar la métrica de accuracy con otras como:\n",
    "- Precision: proporción de predicciones positivas que fueron correctas. Un modelo con alta precisión minimiza falsos positivos.\n",
    "- Recall: Los positivos reales que detectó el modelo. Importa dependiendo del costo de los falsos negativos.\n",
    "- F1 score: Balance entre precisión y recall, relevante cuando el costo de los errores es similar en ambas direcciones.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aac7453",
   "metadata": {},
   "source": [
    "**- ¿Qué información útil nos da una matriz de confusión que no nos da la accuracy?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d41f9c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41a8a1b2",
   "metadata": {},
   "source": [
    "**- En el reporte de clasificación, ¿qué representan `precision`, `recall` y `f1-score`?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d95f0c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "043af8b9",
   "metadata": {},
   "source": [
    "# 5. TensorBoard y Logging\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42310512",
   "metadata": {},
   "source": [
    "**- ¿Qué ventajas tiene usar TensorBoard durante el entrenamiento?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853d44e7",
   "metadata": {},
   "source": [
    "Tensorboard permite visualizar en tiempo real la dinámica del entrenamiento a través de métricas como la loss, el accuracy, entre otros. Esta visualización facilita la detección de problemas como overfitting o underfitting, y ayuda a entender mejor el comportamiento del modelo frente a distintos ajustess. Además, nos permite llevar un registro organizado de cada run, para comparar mejor los resultado al variar diferentes hiperparámetos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f91d7f",
   "metadata": {},
   "source": [
    "**- ¿Qué diferencias hay entre loguear `add_scalar`, `add_image` y `add_text`?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bf9001",
   "metadata": {},
   "source": [
    "Por medio de distintas funciones podemos loguear distintos tipos de resultados que vamos obteniendo al entrenar la red. En este caso `add_scalar` permite guardar valores numéricos que podrían ser las métricas (loss, accuracy); `add_image` es para guardar y visualizar graficos e imágenes. Por último, `add_text` permite registrar texto como comentarios, detalles o anotaciones, útil para documentar los resultados obtenidos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3307a0c",
   "metadata": {},
   "source": [
    "**- ¿Por qué es útil guardar visualmente las imágenes de validación en TensorBoard?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109954b7",
   "metadata": {},
   "source": [
    "Guardar las imágenes de validación es útil porque podemos evaluar visualmente lo que el modelo hizo de manera cuantitativa. En si, el objetivo es encontrar el modelo que logra clasificar las imágenes de diagnóstico médico con mejor presición, por lo que la interpretación visual en este contexto es importante y sirve poder comparar de manera directa en qué imágenes falla más veces y ver si las predicciones desde otro punto de vista tienen sentido."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9ea7ad",
   "metadata": {},
   "source": [
    "**- ¿Cómo se puede comparar el desempeño de distintos experimentos en TensorBoard?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960ef84f",
   "metadata": {},
   "source": [
    "\n",
    "REVISAR\n",
    "\n",
    "\n",
    "Para comparar el desempeño de distintos experimentos en TensorBoard, se pueden guardar los registros de cada entrenamiento en carpetas separadas, especificando un nombre que refleje los hiperparámetros utilizados (por ejemplo, tasa de aprendizaje o tamaño del batch). Luego, al ejecutar TensorBoard sobre la carpeta principal que contiene todos los experimentos, la interfaz detecta automáticamente las distintas ejecuciones y permite visualizar sus curvas de métricas en conjunto. De esta forma, es posible superponer gráficos de loss, accuracy u otras métricas y evaluar cuál configuración del modelo produjo mejores resultados. Esta funcionalidad resulta fundamental para el análisis comparativo y la toma de decisiones durante la etapa de ajuste del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869c92d6",
   "metadata": {},
   "source": [
    "# 6. Generalización y Transferencia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d98da5c",
   "metadata": {},
   "source": [
    "**- ¿Qué cambios habría que hacer si quisiéramos aplicar este mismo modelo a un dataset con 100 clases?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edea5f06",
   "metadata": {},
   "source": [
    "En primer lugar, la última capa debería tener 100 neuronas en lugar de 10, esto es debido a que cada neurona de la última capa devuelve el score de pertenencia a una determinada clase. Con esto ya se puede re-entrenar la red (los pesos ya no serían los mismos) pero probablemente el modelo no sea lo suficientemente complej como para distinguir las 100 clases, por lo que habría que modificar la profundidad del mismo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8649ad6e",
   "metadata": {},
   "source": [
    "**- ¿Por qué una CNN suele ser más adecuada que una MLP para clasificación de imágenes?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aeefbff",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bcc817c2",
   "metadata": {},
   "source": [
    "**- ¿Qué problema podríamos tener si entrenamos este modelo con muy pocas imágenes por clase?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419b1326",
   "metadata": {},
   "source": [
    "Si entrenamos el modelo de esta forma es probable que memorice las pocas imágenes de entrenamiento en lugar de aprender patrones generales, provocando que no generalice bien al ver entradas nuevas.\n",
    "Además, con muy pocos ejemplos, es probable que las imágenes no representen bien la variabilidad natural de esa clase (cambios de iluminación, ángulos, escalas, fondos, etc.). Como resultado, el modelo aprenderá una versión sesgada de cada clase, lo que reduce su capacidad para reconocer correctamente nuevas instancias de esa misma clase. El data augmentation podría ayudar un poco con este problema."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99422715",
   "metadata": {},
   "source": [
    "**- ¿Cómo podríamos adaptar este pipeline para imágenes en escala de grises?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3395379",
   "metadata": {},
   "source": [
    "El pipeline en general sería el mismo, una imagen en escala de grises tiene profundidad de pixel igual a 1, mientras que a color 3. Por lo tanto, la única modificación es que el input size pasa a ser un tercio del original."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54892c6",
   "metadata": {},
   "source": [
    "# 7. Regularización"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d01634b",
   "metadata": {},
   "source": [
    "**- ¿Qué es la regularización en el contexto del entrenamiento de redes neuronales?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ef40ae",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8122ea9e",
   "metadata": {},
   "source": [
    "**- ¿Cuál es la diferencia entre `Dropout` y regularización `L2` (weight decay)?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e8c79f",
   "metadata": {},
   "source": [
    "La diferencia entre ambas técnicas es que dropout inactiva neuronas al azar, esto busca que se formen nuevos caminos con mas protagonismo. Por otro lado weight decay agrega un terimno de pensalizacion en la funcion de costo. Este termino es la norma L2 de los pesos multiplicado por un factor $\\lambda$ (hiperparámetro) que modula su importancia. De esta forma se penalizan aquellas neuronas con pesos de modulo alto y se trabaja en la zona central de la funación de activación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77f8039",
   "metadata": {},
   "source": [
    "**- ¿Qué es `BatchNorm` y cómo ayuda a estabilizar el entrenamiento?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784d733f",
   "metadata": {},
   "source": [
    "Batch Normalization es un técnica de regularización que se utiliza para escalar un batch según la media y el desvio del i componente de los N vectores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5b0e37",
   "metadata": {},
   "source": [
    "**- ¿Cómo se relaciona `BatchNorm` con la velocidad de convergencia?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac43c3f2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c43cc4ee",
   "metadata": {},
   "source": [
    "**- ¿Puede `BatchNorm` actuar como regularizador? ¿Por qué?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0f91ec",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b2e29d0a",
   "metadata": {},
   "source": [
    "**- ¿Qué efectos visuales podrías observar en TensorBoard si hay overfitting?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec53d1b7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "45647e8d",
   "metadata": {},
   "source": [
    "**- ¿Cómo ayuda la regularización a mejorar la generalización del modelo?**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TP_redes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
