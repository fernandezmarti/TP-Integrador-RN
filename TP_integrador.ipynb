{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43c35112",
   "metadata": {},
   "source": [
    "# 1. Dataset y Preprocesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ed54d6",
   "metadata": {},
   "source": [
    "**- ¿Por qué es necesario redimensionar las imágenes a un tamaño fijo para una MLP?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f0443d",
   "metadata": {},
   "source": [
    "\n",
    "Al crear un modelo MPL, antes de entrenar, definimos un número fijo de entradas y por consiguiente un número fijo de neuronas con sus respectivos pesos que se irán actualizando. Si el input son imágenes de distintas dimensiones, después del `flatten`, obtendremos un error de dimension tipo shape porque no tendríamos coincidencia de los pesos de la primera capa.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e55305",
   "metadata": {},
   "source": [
    "**- ¿Qué ventajas ofrece Albumentations frente a otras librerías de transformación como `torchvision.transforms`?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc1c1ac",
   "metadata": {},
   "source": [
    "Albumentations es una librería que nos permite hacer transformaciónes de imágenes como técnica de data aumentation y cuenta con una documentación bien detallada con varios ejemplos para aprender a usar sus funciones.\\\n",
    " Contiene funciones básicas como rotación, traslación y normalización pero además posee otras funcionalidades más complejas que permiten distorsionar la información para generar nuevas entradas como . Además, esta librería no solo funciona con simples imágenes en 2D si no que también permite trabajar con imágenes en 3D (como el caso de las imágenes médicas) y con videos. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7820a8b",
   "metadata": {},
   "source": [
    "**- ¿Qué hace `A.Normalize()`? ¿Por qué es importante antes de entrenar una red?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22a0ddd",
   "metadata": {},
   "source": [
    "`A.Normalize()` es una transformación de Albumentations que aplica varias técnicas de normalización a una imagen para normalizar los valores de sus pixeles. La técnica de normalización específica (standard, image, image_per_channel, min_max, min_max_per_channel) puede seleccionarse con el parámetro normalization. En el caso de la standard se aplica: `img = (img - mean * max_pixel_value) / (std * max_pixel_value)` donde esos parámetros se deben asignar. \\\n",
    "Esto es importante antes de entrenar una red ya que acelera el entrenamiento y evita que entradas de valores muy extremos tengan mucho peso al generar el gradiente. MEJORAR ESTA PARTE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a44fb8",
   "metadata": {},
   "source": [
    "**- ¿Por qué convertimos las imágenes a `ToTensorV2()` al final de la pipeline?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4c76aa",
   "metadata": {},
   "source": [
    "Este es el último paso de la data aumentation y lo debemos hacer porque Albumentations trabaja con imágenes como numpy arrays pero nosotros para entrenar la red en PyTorch necesitamos de tensores, entonces con esa línea de código logramos convertir el array de la imágen después de sus respectivas transformaciones en el formato correcto para poder entrenar la red."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a615afe",
   "metadata": {},
   "source": [
    "# 2. Arquitectura del Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08837055",
   "metadata": {},
   "source": [
    "**- ¿Por qué usamos una red MLP en lugar de una CNN aquí? ¿Qué limitaciones tiene?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289ec934",
   "metadata": {},
   "source": [
    "NO ENTIENDO LA PREGUNTA, TODAVIA NO VIMOS CNN.\\\n",
    "Para la clasificación y procesamiento de imágenes una CNN suele ser la solución más elegída. En este caso usamos un MLP que consiste en un modelo más simple y fácil de implementar, dado que las imágenes se redimensionan a un tamaño pequeño (64x64x3) para poder manejar la cantidad de datos, pero por lo general no es una estrategia elegida dado que una imagen tiene patrones espaciales que la caracterizan (como su textura o bordes específicos) que en este caso, al convertirlo en un vector 1D después del ´flatten´ se pierde esa información estructural que puede ser importante en el caso de querer detectar por ejemplo anomalías en la piel o en muchos casos médicos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799a3019",
   "metadata": {},
   "source": [
    "**- ¿Qué hace la capa `Flatten()` al principio de la red?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7844d14b",
   "metadata": {},
   "source": [
    "La capa ´flatten()´ se encarga de convertir la imágen que está en 2D y varios canales (por lo general 3: R,G,B) en un vector unidimensional ya que al usar un MLP, las capas lineares solo admiten vectores de entrada. En nuestro caso, al trabajar con imágenes de 64x64 en los tres canales, en la primera capa tenemos un vector de 64x64x3 elementos, es decir 12.288."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb57dbd",
   "metadata": {},
   "source": [
    "**- ¿Qué función de activación se usó? ¿Por qué no usamos `Sigmoid` o `Tanh`?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ab4ce7",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TP_redes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
