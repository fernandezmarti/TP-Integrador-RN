{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20ce9329-dfa9-4c9a-a759-43075605a144",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6ccca9e-4fec-44af-a8b7-d034101cb913",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sanit\\OneDrive\\Escritorio\\TP integrador NN\\TP-Integrador-RN\\.venv\\Lib\\site-packages\\albumentations\\__init__.py:28: UserWarning: A new version of Albumentations is available: '2.0.8' (you have '2.0.7'). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "import io\n",
    "from helper import *\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ba3ee6d-5ae2-4750-b49b-b343f19c9876",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7eb85e50-d8ea-4a0d-82b8-dfbfa12ef379",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fdb67cc-e660-4822-a999-ff80aa316a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision.utils as vutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53b1b529-ba09-4afc-a901-b04b3c07ed00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/26 17:32:21 INFO mlflow.tracking.fluent: Experiment with name 'Clasificador_Imagenes' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///c:/Users/sanit/OneDrive/Escritorio/TP%20integrador%20NN/TP-Integrador-RN/mlruns/162407455365887278', creation_time=1750969941089, experiment_id='162407455365887278', last_update_time=1750969941089, lifecycle_stage='active', name='Clasificador_Imagenes', tags={}>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(\"Clasificador_Imagenes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3135b655-4342-4c85-9c68-46ef459de7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_classification_report(model, loader, writer, device, classes, step, prefix=\"val\"):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.numpy())\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    fig_cm, ax = plt.subplots(figsize=(6, 6))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n",
    "    disp.plot(ax=ax, cmap='Blues', xticks_rotation=45)\n",
    "    ax.set_title(f'{prefix.title()} - Confusion Matrix')\n",
    "\n",
    "    # Guardar localmente y subir a MLflow\n",
    "    fig_path = f\"confusion_matrix_{prefix}_epoch_{step}.png\"\n",
    "    fig_cm.savefig(fig_path)\n",
    "    mlflow.log_artifact(fig_path)\n",
    "    os.remove(fig_path)\n",
    "\n",
    "    plot_to_tensorboard(fig_cm, writer, f\"{prefix}/confusion_matrix\", step)\n",
    "\n",
    "    cls_report = classification_report(all_labels, all_preds, target_names=classes)\n",
    "    writer.add_text(f\"{prefix}/classification_report\", f\"<pre>{cls_report}</pre>\", step)\n",
    "\n",
    "    # También loguear texto del reporte\n",
    "    with open(f\"classification_report_{prefix}_epoch_{step}.txt\", \"w\") as f:\n",
    "        f.write(cls_report)\n",
    "    mlflow.log_artifact(f.name)\n",
    "    os.remove(f.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64a152ed-69db-408c-9920-980b864416b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento y validación\n",
    "def evaluate(model, loader, writer, device, classes, epoch=None, prefix=\"val\"):\n",
    "    log_classification_report(model, loader, writer, device, classes, step=epoch , prefix=\"val\")\n",
    "    model.eval()\n",
    "    correct, total, loss_sum = 0, 0, 0.0\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (images, labels) in enumerate(loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            loss_sum += loss.item()\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "            # Loguear imágenes del primer batch\n",
    "            if i == 0 and epoch is not None:\n",
    "                img_grid = vutils.make_grid(images[:8].cpu(), normalize=True)\n",
    "                writer.add_image(f\"{prefix}/images\", img_grid, global_step=epoch)\n",
    "\n",
    "    acc = 100.0 * correct / total\n",
    "    avg_loss = loss_sum / len(loader)\n",
    "\n",
    "    if epoch is not None:\n",
    "        writer.add_scalar(f\"{prefix}/loss\", avg_loss, epoch)\n",
    "        writer.add_scalar(f\"{prefix}/accuracy\", acc, epoch)\n",
    "\n",
    "    return avg_loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2acfa65-34ab-454c-ba1a-b2f8f1f99c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "train_dir = r'skin-dataset-clasification/data/Split_smol/train/'\n",
    "val_dir = r'skin-dataset-clasification/data/Split_smol/val/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d86d4782-1460-4d63-b282-14ac74d1587c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear directorio de logs de tensorboard\n",
    "log_dir = \"runs/experimento_skin\"\n",
    "writer = SummaryWriter(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b7b2f89-33be-4c4f-a499-8704987249ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6356077174637574"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.rand()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "251b58ed-4d28-431f-a8be-2549a20402cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams_space= {\n",
    "    \"model\": (\"CNNClassifier\"),\n",
    "    \"input_size\":  [32,64,128],\n",
    "    \"batch_size\": [16,64,128],\n",
    "    \"lr\": [1e-2,1e-3,1e-4],\n",
    "    \"epochs\": 200,\n",
    "    \"optimizer\":  [\"Adam\"],\n",
    "    \"HFlip\": [0.0,0.5],\n",
    "    \"VFlip\": [0.0,0.5],\n",
    "    \"RBContrast\": [0.0, 0.5],\n",
    "    \"loss_fn\": \"CrossEntropyLoss\",\n",
    "    \"train_dir\": train_dir,\n",
    "    \"val_dir\": val_dir,\n",
    "    \"es_patience\": 5,\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d1097b11-4a9a-402e-b238-6acfe506a76f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modelo número: 0\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/26 17:38:39 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/06/26 17:39:05 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/06/26 17:39:31 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/06/26 17:39:56 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/06/26 17:40:21 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/06/26 17:40:45 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/06/26 17:41:11 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/06/26 17:41:36 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/06/26 17:42:00 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modelo número: 11724138  val: 69.44444444444444\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/26 17:43:25 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/06/26 17:43:50 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/06/26 17:44:15 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/06/26 17:44:40 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/06/26 17:45:05 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/06/26 17:45:29 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/06/26 17:45:54 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/06/26 17:46:19 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/06/26 17:46:44 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/06/26 17:47:10 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/06/26 17:47:44 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/06/26 17:48:09 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/06/26 17:48:33 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/06/26 17:48:58 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/06/26 17:49:23 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modelo número: 277011494  val: 48.888888888888886\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/26 17:50:51 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/06/26 17:51:20 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/06/26 17:51:48 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/06/26 17:52:44 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/06/26 17:53:12 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/06/26 17:53:40 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modelo número: 30229885  val: 68.33333333333333\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/26 17:55:28 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/06/26 17:55:55 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/06/26 17:56:22 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/06/26 17:56:49 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/06/26 17:57:17 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/06/26 17:57:57 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/06/26 17:58:37 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/06/26 18:00:06 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/06/26 18:01:25 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/06/26 18:02:43 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/06/26 18:03:10 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/06/26 18:03:50 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/06/26 18:04:17 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modelo número: 467816092  val: 74.44444444444444\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/26 18:06:00 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/06/26 18:06:29 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/06/26 18:06:57 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/06/26 18:07:25 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/06/26 18:07:52 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/06/26 18:08:33 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/06/26 18:09:00 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/06/26 18:09:28 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/06/26 18:10:08 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/06/26 18:10:35 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/06/26 18:11:41 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modelo número: 57816092  val: 76.11111111111111\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/26 18:13:25 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/06/26 18:13:52 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/06/26 18:14:20 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/06/26 18:14:47 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/06/26 18:15:26 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/06/26 18:15:53 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/06/26 18:16:21 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/06/26 18:17:00 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/06/26 18:17:40 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/06/26 18:18:07 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/06/26 18:18:46 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/06/26 18:19:26 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/06/26 18:20:06 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/06/26 18:21:22 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modelo número: 622988506  val: 73.33333333333333\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/26 18:23:06 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/06/26 18:23:34 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/06/26 18:24:02 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/06/26 18:24:29 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/06/26 18:24:57 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/06/26 18:25:25 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/06/26 18:25:53 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/06/26 18:26:20 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/06/26 18:26:47 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/06/26 18:27:15 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/06/26 18:27:43 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/06/26 18:28:36 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/06/26 18:29:03 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/06/26 18:29:43 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tarin: 79.74137931034483  val: 66.11111111111111\r"
     ]
    }
   ],
   "source": [
    "modelnbr = 0\n",
    "for input_size in hparams_space[\"input_size\"]:\n",
    "    for batch_size in hparams_space[\"batch_size\"]:\n",
    "        for lr in hparams_space[\"lr\"]:\n",
    "            for optimizer in hparams_space[\"optimizer\"]:\n",
    "                for HFlip in hparams_space[\"HFlip\"]:\n",
    "                    for VFlip in hparams_space[\"VFlip\"]:\n",
    "                        for RBContrast in hparams_space[\"RBContrast\"]:\n",
    "                            if np.random.rand() < 0.05:\n",
    "                                print(f\"modelo número: {modelnbr}\", end = \"\\r\")\n",
    "                                modelnbr += 1\n",
    "                                hparams= {\n",
    "                                    \"model\": (\"CNNClassifier\"),\n",
    "                                    \"input_size\":  input_size,\n",
    "                                    \"batch_size\": batch_size,\n",
    "                                    \"lr\": lr,\n",
    "                                    \"epochs\": 200,\n",
    "                                    \"optimizer\": optimizer,\n",
    "                                    \"HFlip\": HFlip,\n",
    "                                    \"VFlip\": VFlip,\n",
    "                                    \"RBContrast\": RBContrast,\n",
    "                                    \"loss_fn\": \"CrossEntropyLoss\",\n",
    "                                    \"train_dir\": train_dir,\n",
    "                                    \"val_dir\": val_dir,\n",
    "                                    \"es_patience\": 5,\n",
    "                                }\n",
    "                                train_transform = A.Compose([\n",
    "                                    A.Resize(hparams[\"input_size\"], hparams[\"input_size\"]),\n",
    "                                    A.HorizontalFlip(p=hparams[\"HFlip\"]),\n",
    "                                    A.VerticalFlip(p=hparams[\"VFlip\"]),\n",
    "                                    A.RandomBrightnessContrast(p=hparams[\"RBContrast\"]),\n",
    "                                    A.Normalize(),\n",
    "                                    ToTensorV2()\n",
    "                                ])\n",
    "                                val_test_transform = A.Compose([\n",
    "                                    A.Resize(hparams[\"input_size\"], hparams[\"input_size\"]),\n",
    "                                    A.Normalize(),\n",
    "                                    ToTensorV2()\n",
    "                                ])\n",
    "                                train_dataset = CustomImageDataset(train_dir, transform=train_transform)\n",
    "                                val_dataset   = CustomImageDataset(val_dir, transform=val_test_transform)\n",
    "                                batch_size = hparams[\"batch_size\"]\n",
    "                                train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "                                val_loader   = DataLoader(val_dataset, batch_size=batch_size)\n",
    "                                device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "                                num_classes = len(set(train_dataset.labels))\n",
    "                                model = CNNClassifier(num_classes=num_classes, input_size = hparams[\"input_size\"]).to(device)\n",
    "                                criterion = nn.CrossEntropyLoss()\n",
    "                                optimizer = optim.Adam(model.parameters(), lr=hparams[\"lr\"]) if hparams[\"optimizer\"]==\"Adam\" else optim.SGD(model.parameters(), lr=hparams[\"lr\"])\n",
    "                                hparams[\"count_params\"] = count_parameters(model)\n",
    "                                with mlflow.start_run():\n",
    "                                    # Log hiperparámetros\n",
    "                                    mlflow.log_params(hparams)\n",
    "                                    best_val_acc = 0\n",
    "                                    best_val_loss = 0\n",
    "                                    best_train_acc = 0\n",
    "                                    best_train_loss = 0\n",
    "                                    best_epoch = 0\n",
    "                                    for epoch in range(hparams[\"epochs\"]):\n",
    "                                        model.train()\n",
    "                                        running_loss = 0.0\n",
    "                                        correct, total = 0, 0\n",
    "                                    \n",
    "                                        for images, labels in train_loader:\n",
    "                                            images, labels = images.to(device), labels.to(device)\n",
    "                                    \n",
    "                                            optimizer.zero_grad()\n",
    "                                            outputs = model(images)\n",
    "                                            loss = criterion(outputs, labels)\n",
    "                                            loss.backward()\n",
    "                                            optimizer.step()\n",
    "                                    \n",
    "                                            running_loss += loss.item()\n",
    "                                            _, preds = torch.max(outputs, 1)\n",
    "                                            correct += (preds == labels).sum().item()\n",
    "                                            total += labels.size(0)\n",
    "                                    \n",
    "                                        train_loss = running_loss / len(train_loader)\n",
    "                                        train_acc = 100.0 * correct / total\n",
    "                                        val_loss, val_acc = evaluate(model, val_loader, writer, device,train_dataset.label_encoder.classes_,epoch=epoch, prefix=\"val\")\n",
    "                                    \n",
    "                                        #print(f\"Epoch {epoch+1}:\")\n",
    "                                        #print(f\"  Train Loss: {train_loss:.4f}, Accuracy: {train_acc:.2f}%\")\n",
    "                                        #print(f\"  Val   Loss: {val_loss:.4f}, Accuracy: {val_acc:.2f}%\")\n",
    "                                    \n",
    "                                        writer.add_scalar(\"train/loss\", train_loss, epoch)\n",
    "                                        writer.add_scalar(\"train/accuracy\", train_acc, epoch)\n",
    "                                    \n",
    "                                        # Log en MLflow\n",
    "                                        mlflow.log_metrics({\n",
    "                                            \"train_loss\": train_loss,\n",
    "                                            \"train_accuracy\": train_acc,\n",
    "                                            \"val_loss\": val_loss,\n",
    "                                            \"val_accuracy\": val_acc\n",
    "                                        }, step=epoch)\n",
    "                                        if val_acc > best_val_acc:\n",
    "                                            best_val_acc = val_acc\n",
    "                                            best_val_loss = val_loss\n",
    "                                            best_train_acc = train_acc\n",
    "                                            best_train_loss = train_loss\n",
    "                                            best_epoch = epoch\n",
    "                                            # Guardar modelo\n",
    "                                            torch.save(model.state_dict(), \"mlp_model.pth\")\n",
    "                                            #print(\"Modelo guardado como 'mlp_model.pth'\")\n",
    "                                            mlflow.log_artifact(\"mlp_model.pth\")\n",
    "                                            mlflow.pytorch.log_model(model, artifact_path=\"pytorch_model\")\n",
    "                                        elif epoch > best_epoch + hparams[\"es_patience\"]:\n",
    "                                            #print(\"Early Stopping\")\n",
    "                                            break\n",
    "                                            \n",
    "                                    mlflow.log_metrics({\n",
    "                                            \"train_loss\": best_train_loss,\n",
    "                                            \"train_accuracy\": best_train_acc,\n",
    "                                            \"val_loss\": best_val_loss,\n",
    "                                            \"val_accuracy\": best_val_acc,\n",
    "                                            \"best_epoch\": best_epoch\n",
    "                                        }, step=epoch+1)                                                \n",
    "                                print(f\"tarin: {best_train_acc}  val: {best_val_acc}\", end = \"\\r\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585580ed-3db0-4687-8ab5-a09abacc621b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594da669-b48e-4307-bd29-11cd988fb4a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34241d72-902a-491a-a1e5-a6ec756ab54a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
